{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Part 8 - Transfer Learning (Exercises).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1dda6cf0a83e47ea964b9856951b53a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cd6d0ce95de3415cb2667f52fa8de2a1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2c7932b198704cc99ff5447d7b519f6c",
              "IPY_MODEL_e4c36dd8fd3e43bcae2c91b19516a45a"
            ]
          }
        },
        "cd6d0ce95de3415cb2667f52fa8de2a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c7932b198704cc99ff5447d7b519f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_70e8cb64baf74fc284ad825977a84dfa",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 32342954,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 32342954,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e49f3919d9174d52ba67ea506123ee37"
          }
        },
        "e4c36dd8fd3e43bcae2c91b19516a45a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_81d9607cb25349c59f769eab08fc9749",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 30.8M/30.8M [13:17&lt;00:00, 40.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_604a77f884ad4f81812c4e170e456d46"
          }
        },
        "70e8cb64baf74fc284ad825977a84dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e49f3919d9174d52ba67ea506123ee37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81d9607cb25349c59f769eab08fc9749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "604a77f884ad4f81812c4e170e456d46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willclarktech/deep-learning-v2-pytorch/blob/master/intro-to-pytorch/Part%208%20-%20Transfer%20Learning%20(Exercises).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKpFQawa3MR4",
        "colab_type": "text"
      },
      "source": [
        "# Transfer Learning\n",
        "\n",
        "In this notebook, you'll learn how to use pre-trained networks to solved challenging problems in computer vision. Specifically, you'll use networks trained on [ImageNet](http://www.image-net.org/) [available from torchvision](http://pytorch.org/docs/0.3.0/torchvision/models.html). \n",
        "\n",
        "ImageNet is a massive dataset with over 1 million labeled images in 1000 categories. It's used to train deep neural networks using an architecture called convolutional layers. I'm not going to get into the details of convolutional networks here, but if you want to learn more about them, please [watch this](https://www.youtube.com/watch?v=2-Ol7ZB0MmU).\n",
        "\n",
        "Once trained, these models work astonishingly well as feature detectors for images they weren't trained on. Using a pre-trained network on images not in the training set is called transfer learning. Here we'll use transfer learning to train a network that can classify our cat and dog photos with near perfect accuracy.\n",
        "\n",
        "With `torchvision.models` you can download these pre-trained networks and use them in your applications. We'll include `models` in our imports now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCp-sJrj3MR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWKbmeOA3XmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!if [ ! -f \"Cat_Dog_data.zip\" ]; then wget https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip; fi\n",
        "!if [ ! -d \"Cat_Dog_data\" ]; then unzip Cat_Dog_data.zip; fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu-PW8HM3MR8",
        "colab_type": "text"
      },
      "source": [
        "Most of the pretrained models require the input to be 224x224 images. Also, we'll need to match the normalization used when the models were trained. Each color channel was normalized separately, the means are `[0.485, 0.456, 0.406]` and the standard deviations are `[0.229, 0.224, 0.225]`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l7qRGhk3MR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = 'Cat_Dog_data'\n",
        "means = [0.485, 0.456, 0.406]\n",
        "stds = [0.229, 0.224, 0.225]\n",
        "\n",
        "# TODO: Define transforms for the training data and testing data\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(255),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(means, stds),\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(255),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(means, stds),\n",
        "])\n",
        "\n",
        "# Pass transforms in here, then run the next cell to see how the transforms look\n",
        "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7Zn-X-s3MR-",
        "colab_type": "text"
      },
      "source": [
        "We can load in a model such as [DenseNet](http://pytorch.org/docs/0.3.0/torchvision/models.html#id5). Let's print out the model architecture so we can see what's going on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Xodr_JhG3MR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1dda6cf0a83e47ea964b9856951b53a5",
            "cd6d0ce95de3415cb2667f52fa8de2a1",
            "2c7932b198704cc99ff5447d7b519f6c",
            "e4c36dd8fd3e43bcae2c91b19516a45a",
            "70e8cb64baf74fc284ad825977a84dfa",
            "e49f3919d9174d52ba67ea506123ee37",
            "81d9607cb25349c59f769eab08fc9749",
            "604a77f884ad4f81812c4e170e456d46"
          ]
        },
        "outputId": "4fb5ecd8-4951-44cf-ee75-d5e8f632d81c"
      },
      "source": [
        "model = models.densenet121(pretrained=True)\n",
        "model"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/checkpoints/densenet121-a639ec97.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1dda6cf0a83e47ea964b9856951b53a5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=32342954.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseNet(\n",
              "  (features): Sequential(\n",
              "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu0): ReLU(inplace=True)\n",
              "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (denseblock1): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition1): _Transition(\n",
              "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock2): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition2): _Transition(\n",
              "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock3): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer17): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer18): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer19): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer20): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer21): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer22): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer23): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer24): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition3): _Transition(\n",
              "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock4): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8NxQZa03MSD",
        "colab_type": "text"
      },
      "source": [
        "This model is built out of two main parts, the features and the classifier. The features part is a stack of convolutional layers and overall works as a feature detector that can be fed into a classifier. The classifier part is a single fully-connected layer `(classifier): Linear(in_features=1024, out_features=1000)`. This layer was trained on the ImageNet dataset, so it won't work for our specific problem. That means we need to replace the classifier, but the features will work perfectly on their own. In general, I think about pre-trained networks as amazingly good feature detectors that can be used as the input for simple feed-forward classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7FC2uaz3MSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze parameters so we don't backprop through them\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "from collections import OrderedDict\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                          ('fc1', nn.Linear(1024, 500)),\n",
        "                          ('relu', nn.ReLU()),\n",
        "                          ('fc2', nn.Linear(500, 2)),\n",
        "                          ('output', nn.LogSoftmax(dim=1))\n",
        "                          ]))\n",
        "    \n",
        "model.classifier = classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1hC6Syn3MSG",
        "colab_type": "text"
      },
      "source": [
        "With our model built, we need to train the classifier. However, now we're using a **really deep** neural network. If you try to train this on a CPU like normal, it will take a long, long time. Instead, we're going to use the GPU to do the calculations. The linear algebra computations are done in parallel on the GPU leading to 100x increased training speeds. It's also possible to train on multiple GPUs, further decreasing training time.\n",
        "\n",
        "PyTorch, along with pretty much every other deep learning framework, uses [CUDA](https://developer.nvidia.com/cuda-zone) to efficiently compute the forward and backwards passes on the GPU. In PyTorch, you move your model parameters and other tensors to the GPU memory using `model.to('cuda')`. You can move them back from the GPU with `model.to('cpu')` which you'll commonly do when you need to operate on the network output outside of PyTorch. As a demonstration of the increased speed, I'll compare how long it takes to perform a forward and backward pass with and without a GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOHl95YW3MSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddKlEhZh3MSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ee04e32b-87fc-454a-b9fc-d17d7e7c2456"
      },
      "source": [
        "for device in ['cpu', 'cuda']:\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "    # Only train the classifier parameters, feature parameters are frozen\n",
        "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for ii, (inputs, labels) in enumerate(trainloader):\n",
        "\n",
        "        # Move input and label tensors to the GPU\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        outputs = model.forward(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if ii==3:\n",
        "            break\n",
        "        \n",
        "    print(f\"Device = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device = cpu; Time per batch: 4.686 seconds\n",
            "Device = cuda; Time per batch: 0.016 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qzv9YGw3MSL",
        "colab_type": "text"
      },
      "source": [
        "You can write device agnostic code which will automatically use CUDA if it's enabled like so:\n",
        "```python\n",
        "# at beginning of the script\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "...\n",
        "\n",
        "# then whenever you get a new Tensor or Module\n",
        "# this won't copy if they are already on the desired device\n",
        "input = data.to(device)\n",
        "model = MyModule(...).to(device)\n",
        "```\n",
        "\n",
        "From here, I'll let you finish training the model. The process is the same as before except now your model is much more powerful. You should get better than 95% accuracy easily.\n",
        "\n",
        ">**Exercise:** Train a pretrained models to classify the cat and dog images. Continue with the DenseNet model, or try ResNet, it's also a good model to try out first. Make sure you are only training the classifier and the parameters for the features part are frozen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRcALrPjE0gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.densenet121(pretrained=True)\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "classifier = nn.Sequential(\n",
        "    nn.Linear(1024, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 2),\n",
        "    nn.LogSoftmax(dim=1),\n",
        ")\n",
        "model.classifier = classifier\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "learning_rate = 0.001\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "device = 'cuda'\n",
        "model.to(device)\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "num_epochs = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnyTOP1e3MSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "fb92b3c2-d530-4d1d-840e-46c7d3c6429a"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "  train_loss = 0\n",
        "  test_loss = 0\n",
        "  accuracy = 0\n",
        "\n",
        "  model.train()\n",
        "  for x, (images, labels) in enumerate(trainloader):\n",
        "    # if x > 1:\n",
        "    #   break\n",
        "\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    log_probs = model(images)\n",
        "    loss = criterion(log_probs, labels)\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for x, (images, labels) in enumerate(testloader):\n",
        "      # if x > 1:\n",
        "      #   break\n",
        "\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      log_probs = model(images)\n",
        "      loss = criterion(log_probs, labels)\n",
        "      test_loss += loss.item()\n",
        "\n",
        "      _, top_class = log_probs.topk(1, dim=1)\n",
        "      equals = (top_class == labels.view(*top_class.shape)).type(torch.FloatTensor)\n",
        "      accuracy += torch.mean(equals)\n",
        "\n",
        "  train_losses.append(train_loss / len(trainloader))\n",
        "  test_losses.append(test_loss / len(testloader))\n",
        "\n",
        "  print(f'Epoch: {epoch+1}/{num_epochs}')\n",
        "  print(f'Train loss: {train_losses[-1]}')\n",
        "  print(f'Test loss: {test_losses[-1]}')\n",
        "  print(f'Test accuracy: {accuracy*100/len(testloader)}%')\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/2\n",
            "Train loss: 0.18506293500434945\n",
            "Test loss: 0.05580049406271428\n",
            "Test accuracy: 98.0078125%\n",
            "Epoch: 2/2\n",
            "Train loss: 0.15446201258931647\n",
            "Test loss: 0.03708164454437792\n",
            "Test accuracy: 98.4375%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NluR2wZO9IBd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "c1d69cd6-6687-4dde-fa84-4d34e82dfed4"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(test_losses, label='Validation loss')\n",
        "plt.legend(frameon=False)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe02765f9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvUAAAHwCAYAAAAmZ5CjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdeXxU1f3/8fcJ2QdISCCAhACyK1YBRVkqiAIqBVGxtvq1gnX7ol/FrUVcALUFtBTRgvX7RUH6q1SrhSiKgOzggoLagqjsYQkiCQmQhYTk/P6YmTCTySQTMpBceD0fjzxucs/cc++Ay3tOzjkfY60VAAAAAOeKqO0HAAAAAFAzhHoAAADA4Qj1AAAAgMMR6gEAAACHI9QDAAAADkeoBwAAAByOUA8AAAA4HKEeAAAAcDhCPQAAAOBwhHoAAADA4Qj1AAAAgMMR6gEAAACHi6ztB6jrjDE7JDWUtLOWHwUAAABnttaSDltr21T3QkJ91RrGxcUlde7cOam2HwQAAABnrs2bN6ugoOCkriXUV21n586dk9avX1/bzwEAAIAzWPfu3bVhw4adJ3Mtc+oBAAAAhyPUAwAAAA5HqAcAAAAcjlAPAAAAOByhHgAAAHA4Qj0AAADgcIR6AAAAwOEI9QAAAIDDEeoBAAAAhyPUAwAAAA5HqAcAAAAcjlAPAAAAOByhHgAAAHA4Qj0AAADgcIR6AAAAwOEI9XVUZm6B8ouO1/ZjAAAAwAEia/sBULG756zXf/bmqnH9GKUlxalVskstk+LVKileacnxSkuKV0qDGBljavtRAQBAGBhj1LdvX61YsaJG/fTr108rV66UtTY8DxYGs2fP1siRIzVr1iyNGDGith/njESor6N2ZeVJkg4ePaaDR49pQ0ZOwGtioyLUspE74HuDfivPMbVRvGKj6p3uxwYAwLGqO1BGQEVdQqivg/KLjiu5fowKiktUXBL8U3Zhcam2HDiqLQeOVtjerGGs0pLi3SP8yf7hP9kVzSg/AAA+xo0bF3DuxRdfVG5urh588EElJib6tV100UVhvf/mzZsVHx9f437mzJmj/Pz8MDwRnIRQXwfFR0dq+aP9VFJqlZlboIysfGVku792Zedrt+f7nPziSvvZf7hQ+w8Xat3O7IA2V3Q9tUzyBH1P6HeHf5daJMYpOpLlFgCAs8v48eMDzs2ePVu5ubkaPXq0WrdufUrv36lTp7D0k5aWFpZ+4CwktzqsXoRRaqN49WrXWL/qkabfXd1J02/ppvfu76Ovnx6ob8YN1IL/6aPpt3TT76/upF/3SFPvdslqmRSnehGVj8LnFZXou/1HtPjbHzVzzQ49lb5JI2Z9oSv+tEKdnlqo3pOW6df/+5l+/86/NX35Vr3/zT59sztHOflFdWqOHgAAtaFfv34yxqioqEjPPPOMOnbsqJiYmLLpOLm5uXrhhRfUv39/paamKjo6Wk2aNNHQoUP16aefVtinMUb9+vXzOzd+/HgZY7RixQq988476tGjh+Lj45WUlKRf/epX2rt3b9Bn87VixQoZYzR+/Hh9/fXXGjx4sBITExUfH6++ffvqk08+qfCZMjMzNXLkSKWkpCguLk4XXXSR3njjDb/+amr9+vW68cYblZKSopiYGLVq1UqjRo1SZmZmwGt//PFHPfroo+rYsaNcLpcSExPVsWNHjRgxQtu3by97nbVWb7zxhnr16qUmTZooNjZWLVu21KBBg/TWW2/V+JnrIkbqHSwhLkoJLRLUpUVCQFtxSan25RS4R/ezTozu7/KM+h89FnxnnVIr7c0p0N6cAn26PSugvUFspP/ofpKrbMT/nMRYRdbjsyIA4Oxw44036osvvtA111yjYcOGKSUlRZJ7Ks0TTzyhyy+/XIMHD1ajRo2UkZGh9957TwsXLtT777+vq6++OuT7zJgxQ++9956GDh2qvn376vPPP9dbb72lb775Rl9//bViYmJC6ufLL7/U888/r549e+rOO+9URkaG3n33XV155ZX6+uuv1bFjx7LXHjhwQD179tSuXbt0+eWXq1evXtq/f79GjRqlgQMHVu8PKogFCxboxhtvlLVWw4cPV6tWrbR+/Xq98sorSk9P15o1a9SmTRtJUn5+vnr37q1t27ZpwIABGjJkiKy12rVrl9LT0zV8+HCde+65kqQnnnhCEydOVJs2bfTLX/5SCQkJyszM1BdffKF//vOfuvnmm8Py/HUJof4MFVUvQq2SXWqV7NLP2/u3WWt1KL+4bEpPRlaez/f5yjxcqMoG448UHtemfYe1ad/hgLZ6EUYtEuPKAn+aZ8eelp75/A1jo8L8TgEAqD27du3Sxo0b1bhxY7/znTt31r59+wLO79mzRz169NBDDz1UrVD/0Ucf6YsvvtAFF1xQdu6WW27R3LlzlZ6erl/+8pch9fPBBx8ELPB99dVXde+992ratGmaMWNG2fnHH39cu3bt0u9+9ztNnjy57Pzo0aPVo0ePkJ89mKNHj+r222/X8ePHtWLFCv385z8va5s8ebLGjBmje+65R4sXL5YkLV26VNu2bdPo0aM1depUv76Kiop07Ngxv/fUokULbdy4MWCdwsGDB2v87HURof4sZIxRkitaSa5oXdQyMaD92PES7TnkHuXf7TO6753bX1BcErTvklJb9gGhIo3iozwLdl1KS4rzjPC7lJYcr2YNY6ucNgQAqB2tx3xQ248Qsp2TBp+2ez377LMBwV2SEhICf4suSampqRo+fLhefvllZWRkhDz//YEHHvAL9JJ01113ae7cuVq3bl3Iob53794BO/bccccduv/++7Vu3bqyc0VFRZo7d64SEhL05JNP+r3+wgsv1G9+8xvNnDkzpHsGk56eruzsbP3617/2C/SS9Mgjj+ivf/2rlixZEvDnFBcXF9BXdHS0oqOj/c5FRUWpXr3AnQAr+vs6ExDqESAmsp7aNqmvtk3qB7RZa3XwaJEysj2j+1kF2pWdVxb+Dxw5VkGPJxzKL9ah/Fx9syc3oC26XoRSG8X57dbj/b5lo3i5YvjHFQBQt1Q2Yr127VpNmzZNn376qQ4cOKCioiK/9r1794Yc6i+++OKAcy1btpQkHTp0KOTnraifqKgoNW3a1K+f77//XgUFBbr44ovVoEGDgGv69OlT41C/YcMGSVL//v0D2iIjI3X55Zdr586d+uqrr5SWlqa+ffuqRYsWmjRpkjZs2KBrr71WvXv31kUXXRQQ3m+99Va9/PLLOu+88/TLX/5Sffv2Vc+ePYN+2DoThC0lGWNSJT0j6WpJyZIyJc2XNMFaG9I/bcaYAZ7rL/J8JUlaa63tU8k19ST9StK9ktpLaihpj6S1kv5krd10su8JgYwxatIgRk0axKh7q6SA9oKiEu055DO6X+6r6Hhp0L6LSkq1/WCeth/Mq7C9cf3osrn77pH+Ezv3NKkfowhG+QEAp1mzZs0qPD9v3jwNHz5csbGxGjBggNq2bSuXy6WIiAitWLFCK1eu9JsuUpXy22lK7uArSSUlwX+DHko/3r58+8nNdQ++NW3atMLXBztfHd57NG/evMJ27/mcHHetnoYNG+qzzz7TuHHj9N5772nRokWS3CPvo0aN0pNPPqmoKPc036lTp+rcc8/VrFmzNGnSJE2aNEmRkZG69tprNWXKFLVr167Gz1/XhCXUG2PaSvpEUoqkdEnfSeoh6UFJVxtjeltrA1dcBrpP0nWSCiVtlTvUV+VNSb+UO8j/S9IRSRdIul3SLcaYa6y1y6r3jnCy4qLrqX3TBmrfNPBTfWmp1YEjxzwLdvNOLN71TPM5eLSogh5POHi0SAePFlVYiCsmMqIs5Pvty+/5mUJcAFAzp3NKi5MEq/ny1FNPKTo6Wl9++aU6d+7s13bPPfdo5cqVp+PxTlrDhg0luXebqUiw89XhHTXfv39/he3e3W98R9dTU1P12muvyVqrb7/9VsuWLdP06dP1zDPPqLS0VM8++6wkqV69eho9erRGjx6tAwcOaM2aNfrHP/6hf/7zn9q0aZM2bdoU8uJipwjXSP0MuQP9A9bal70njTF/lvSQpD/IPZJelcmSnpD7Q0FLSTsqe7Ex5hK5A/0mST2stfk+bSMlvS7pSUmE+jogIsKoWUKsmiXEqkebwM9rR48dLwv63vn73sC/51B+pYW4jh2vvBBX04YxapXkOrF4N/lE+KcQFwAg3LZu3arzzz8/INCXlpZqzZo1tfRUoevUqZPi4uL073//W0eOHAmYghOO99C1a1dJ7u02f/vb3/q1HT9+XKtXr5YkdevWLeBaY4zOP/98nX/++Ro2bJjS0tI0f/78slDvKyUlRTfccINuuOEGXXnllVq2bJk2btyo7t271/g91CU1DvWeUfqBknZKml6ueZykuyXdZox5xFpb8bwKD2tt2catIYascz3Hpb6B3iPdc2wSSkeoffVjItW5eUN1bt4woK2sEFf5xbshFuL68fAx/Xj4WIWFuOKj652Y1uNTdTctKV6pjeIpxAUAqLbWrVtry5Yt2rdvn8455xxJ7nVp48eP17ffflvLT1e16Oho3XzzzZo9e7aee+45v91vvvnmG82ZM6fG9xg2bJiSkpI0d+5c3XfffbrsssvK2l588UXt2LFDV111Vdm6g02bNqlx48YBU3+8vzXw7nJz7Ngxffnll+rdu7ff64qLi5Wdne332jNJOEbqr/AcF1tr/SZMW2uPGGPWyh36L5O0NAz38+WdL9/fGBNnrS3wafuF5/hxmO+JWuAtxJXaKF5qG9ieW1AcsBf/7ux87crO076cQpWUBh/lz/cU4vpu/5GANmOkcxLi1DIpzr0fv0/gT0uKV2J8FKP8AIAADz30kO6991517dpVN954o6KiorR27Vp9++23GjJkiN5///3afsQqTZo0ScuWLdPzzz+vzz//XL169VJmZqbefvttXXvttZo/f74iIk5+4Kt+/fp6/fXXddNNN6lv37666aablJaWpvXr12vx4sVq1qyZXn311bLXL1myRI899ph69uypDh06KCUlRXv27FF6eroiIiL02GOPSZIKCgrUp08ftWvXTt27d1erVq1UWFioJUuWaPPmzRo6dGjAb1DOBOEI9d4qBT8Ead8id6jvoDCHemvtRmPMVLmn+HxnjFkg95z68+VecPsPuaffVMkYsz5IU3hqNuOUqqoQV2ZOoXaV7diT77cv/5FKCnFZn0Jcn20PHOX3FuLyHeH3FuNqnhirKApxAcBZ6Z577lFMTIxefPFFvfHGG4qLi9PPf/5zzZo1S++++64jQn3Tpk31ySefaOzYsfrwww/1+eefq2PHjpoxY4ZcLpfmz59fNvf+ZF133XVau3at/vjHP2rRokXKzc1Vs2bNdO+99+qpp54q+y2HJA0aNEgZGRlatWqV0tPTdfjwYTVv3lwDBgzQww8/rF69ekmSXC6XJk+erOXLl+uTTz7R/Pnz1aBBA7Vt21avvPKK7rjjjho9c11lbGVVhkLpwJj/lXSXpLustQF7Gxlj/iBprKSx1tqJ1ei3tdxz6ivd/cbz2nskTZXku3HpeklPWms/CvF+QUN9t27d4tevD9YMJ7PWKie/WLuyfUb3PcW4dmcXaF9uQaWFuCrjLcRV0eJdCnEBAJzsiSee0B//+Ed99NFHGjRoUG0/zhmje/fu2rBhwwZrbbUn/Dt642/jnvcwTdIouUfk/5+kHLm3w5wqaaEx5n5rbfm5/gGC/eF5wn7gCg2cEYwxauSKVqNKCnHt9RTi8o7sexfvZmTnK7/o5AtxJcZHnai267d410UhLgBAneC7JsDrP//5j1566SUlJSWpb9++tfRkKC8cod5bRSjYbv7e84H7ENbc7ZL+R9JUa+0kn/NrjDFDJG2XNMkY84a1tuJtUYBKxETW07lN6uvcSgtx5buLcWUVnPg+O18/Hq58/+Gc/GLlBCnEFVXPvYYgrVzg9/5MIS4AwOlw8cUXq127durSpYtcLpe2bNmiDz74QKWlpXr11VcVGxtb248Ij3Akg+89xw5B2tt7jsHm3NeEdzHs8vIN1tr9xpjvJHWVe94/82cQVv6FuBoFtBcWlwRZvFt1Ia7iEqsdB/O0o5JCXC2T4tWqgmJcKQ0oxAUACI977rlH8+fP19y5c3XkyBElJiZq0KBBevTRR9WvX7/afjz4CEeo9wbqgcaYCN8dcIwxDST1lpQv6bMw3Ks8b9WAYNtWes9XXtUIOAVio0IrxOWe1pPnt0VnqIW4vgpSiMsb+H2n9lCICwBQXePGjdO4ceNq+zEQghqHemvtNmPMYrl3uLlP0ss+zRMkuSS96rtHvTGmk+fa72p4+9Vyj9Y/bIx511pbNo/BGHOvpFRJ+yXV/Q1hcVapqhBX3rHjZQG//L78oRTi2nrgqLZWUojLParvGd1Pjiv7vnF9CnEBAOBE4ZqYO0rSJ5JeMsZcKWmzpEvl3sP+B7mrxPra7Dn6pQdjTB9Jd3p+9E5ibm+Mme19jbV2hM8lMyTdKulnkn4wxrwn99z9bpL6SyqRdJ+1NvhqRqAOclVRiGv/4ULtysrzm97j/f5QiIW4vth5KKDNW4irbGpP8onvWzSKU0wko/wAANRFYQn1ntH6iyU9I/f+8NdKypR7Z5oJ1trA9FCxdnIvfvWVUu7cCJ/7HjXG9Jb0sKQbJN0iKVrST5L+KelP1tp11X5DQB3m3SqzRWJclYW4fHftycjO196cghoV4mreMPbEfvzJrhPTeyjEBQBArarxPvVnOmPM+m7dunVjn3qcCbyFuDI81Xb9pvdUUYirKg1iIv0r7vp8f05iHIW4AACowlm7Tz2A6omqF+EO28nx6qPGfm3eQlzlR/h3ZeeFVIjryLHj2rTvsDbtOxzQVi/C6JzEWLVKcgUs3qUQFwAANUeoByDJvxDXhVUU4iq/eDeUQly7swu0O7ugwvbE+KgTI/zlRvqbJ8RRiAsAgCoQ6gGEpKpCXFl5RWULdv335c8LuRDXvyspxOW/Lz+FuAAA8MX/DQHUmDFGjevHqHH94IW49hw6EfZ9d+vJyM7XsTAU4vIu2G3pWcRLIS4AwNmEUA/glIuNqqd2KQ3ULqXiQlw/HT3mV3n3RDGuAh08WvkofyiFuMpP7WmVTCEuAMCZhVAPoFZFRBg1bRirpg1jdUnrigtx7T50YltO35H+3TUsxJXSIKYs4Pst3k1yUYgLwCkzYsQIvfHGG9qxY4dat24tSdq5c6fatGmj22+/XbNnzw6pn9mzZ2vkyJGaNWuWRowYcVqft7b169dPK1euFLs4nkCoB1CnuWIi1alZQ3VqFrwQlzvwnxjd9470V1WI68CRYzpwpOJCXHFR9fzm7/uG/1QKcQFnpFtvvVVvvvmmpk+frlGjRlX62oEDB2rJkiX617/+peuvv/40PeGpMX78eE2YMEHLly9Xv379avtxcJII9QAcy7cQV8+2yQHthwuLleFdvJud77dzT1WFuAqKS/T9j0f0/Y/BC3G19Nua01U2vacRhbgAR7rrrrv05ptvaubMmZWG+p07d+rjjz9W8+bNNWTIkLDcu0WLFtq8ebMSEhLC0l84TZw4UWPGjFGLFi1q+1FQCUI9gDNWw9godWmRoC4tAv8nebykVPs8hbi8xbh2+0zvOVIYvBCXtdK+3ELtyy3U5zuyA9obxET6BX7f7ynEBdRd/fr1U4cOHfTVV19pw4YN6tatW4Wve+2112St1ciRIxUZGZ4oFRUVpU6dOoWlr3Br3ry5mjdvXtuPgSrwfxYAZ6VITyGuPu0b65ZL0/T4NZ0149buWvA/P9e/xw3U108PUPp9vfXyr7vqsUEddfPFLdXz3GS1SIxTVRvqHDl2XN9mHtbCjfv16qrtenL+Rt322jr1fWGFOj31kX7+/DLdOvMzPf6v/+iVFdv0wb8ztXFvrnILKp8uBODUu+uuuyRJ//d//1dhe0lJiWbNmiVjjO68805J0vz58/Vf//Vf6tChg1wul1wul7p3766XXnpJpaXBd/fytXPnThljKpwbv3XrVt10001q1KiRXC6XevXqpQ8++CBoX8uXL9fdd9+t8847Tw0bNlRcXJy6dOmiCRMmqLCw0O+1rVu31oQJEyRJV1xxhYwxZV9eI0aMkDFGO3fuDLjX22+/rcsvv1wJCQmKi4vTBRdcoIkTJ+rYscBNDlq3bq3WrVsrLy9Pjz32mNLS0hQTE6N27dpp8uTJYZkfX1paqr/+9a+65JJLVL9+fblcLl1yySV65ZVXKvy7WL16tYYMGaLU1FTFxMSoWbNmuuyyy8r+TLx+/PFHPfroo+rYsaNcLpcSExPVsWNHjRgxQtu3b6/xc4cDI/UAUI4xRonx0UqMr7gQV9HxUu3NKdCuLP/R/eoW4lqrrIB2byEuv335PXP7KcQFnHq33367nnjiCc2dO1dTpkxRfHy8X/vChQu1d+9eDRgwQG3atJEkjRkzRhEREbr00kvVokUL5ebmatmyZXrwwQf1xRdf6G9/+9tJP8+WLVvUs2dPZWVl6ZprrtFFF12krVu3atiwYbrmmmsqvGby5Mn67rvv1KtXLw0ePFiFhYVau3atxo8frxUrVujjjz9WvXrudUGjR4/W/PnztXLlSt1+++3VWgg7duxYTZw4UY0bN9Ytt9yi+vXra+HChRo7dqwWLVqkxYsXKzo62u+a4uJiDRo0SPv27dM111yjyMhIzZ8/X2PGjFFhYaHGjRt30n9WknTbbbfpzTffVMuWLXXnnXfKGKN58+Zp1KhRWrNmjf7+97+Xvfajjz7S4MGD1bBhQw0dOlQtWrRQdna2Nm/erBkzZpQ9S35+vnr37q1t27ZpwIABGjJkiKy12rVrl9LT0zV8+HCde+65NXrucCDUA0A1RUdGqE1jl9o0dgW0eQtxubfm9Km66/l+/+HCCno8oapCXC0S4zzz9+PUKsl1YsvO5HjVpxAXUGNNmjTRsGHD9Pbbb+vtt98OGDn3juDffffdZec++OADtW3b1u91paWlGjlypObMmaP7779fl1566Uk9z3333aesrCy9+OKLevDBB8vOp6ena9iwYRVeM2PGDLVp0yZgbc9TTz2l5557Tu+8845uvvlmSe5Qn5OTo5UrV2rEiBEhL5T99NNPNXHiRLVs2VLr1q1Ts2bNJLnn319//fVasGCB/vSnP2ns2LF+1+3bt08XXnihlixZori4OEnSuHHj1KFDB02dOlVjx45VVFRUSM9Q3ty5c/Xmm2+qa9euWrVqlerXdxdLfO6559S3b1+9+eabGjx4sG655RZJ7r/L0tJSrVixQhdeeKFfXwcPHiz7funSpdq2bZtGjx6tqVOn+r2uqKiowt9K1Ab+DwAAYeRbiKtbWvBCXBnlK+9mhVaIa2dWvnZm5VfYnuyK9qu26zvK37RBLIW4UDPj694CzqDGB34oro67775bb7/9tmbOnOkX6jMzM/Xhhx8qJSVF1113Xdn58oFekiIiIvTggw9qzpw5WrRo0UmF+j179mjJkiVq06aN7r//fr+26667Tn379tXKlSsDrgs2avzQQw/pueee06JFi8pC/cl6/fXXJUlPPvlkWaCXpMjISE2ZMkUffvihZs6cGRDqJemll14qC/SSyv4858yZo++//15dunSp0TNNmjSpLNBLksvl0uTJk3XVVVdp5syZZaHey/dZvBo3bhxwrqLXRUdHB/w2orYQ6gHgNAq1EFdGlnvHHnfgzwupEFdWXpGy8iouxBUdGaGWjeLKqu2WTe9JjlfLRvGKi2aLTsCrf//+atu2rdauXavNmzerc+fOkqRZs2bp+PHjGjFihN9oclZWll544QV9+OGH2r59u/Ly/Ctg792796Se46uvvpIk9enTp2y6jC/vXu3l5eXladq0aZo3b55++OEHHTlyxG+++sk+j68NGzZIcv9ZldehQwelpqZqx44dys3N9dvRJyEhQe3atQu4pmXLlpKkQ4cCtxiuzjNFRERU+NuGvn37ql69emV/ppJ7C9N//etfuvTSS3XzzTfriiuuUO/evZWamhpwbYsWLTRp0iRt2LBB1157rXr37q2LLrqowr+X2kKoB4A6oqpCXPlFxwOn9Xh+3nOoQEUlwUf5i46XattPedr2U16F7SkNYvz25ffdm79J/Ri26MRZxbsI9vHHH9fMmTM1ZcoUWWv12muvyRhTtphWknJycnTJJZdox44d6tGjh37zm98oKSlJkZGRysnJ0bRp0056ekZurvs3Dk2bNq2w3XeE3Ku4uFj9+/fXunXr1KVLF918881q0qRJ2YeQCRMmhGW6iPfZgu2K07x5c2VkZCgnJ8cv1CcmBq5TklS2i1BJSfA1SaE8U1JSUoUj55GRkWrcuLEOHDhQdu6GG27QggULNGXKFL3++ut69dVXJUndu3fXxIkTNWDAAElSw4YN9dlnn2ncuHF67733tGjRIknu0fxRo0bpySefPOkpQ+FEqAcAh4iPrrwQ14+HC8uq7Wb47M2fkZUXciGuL3cFL8Tlvy8/hbjOOjWc0uI0I0eO1NNPP605c+Zo4sSJWr16tbZv367+/fv7jTTPnDlTO3bs0Lhx4zR+/Hi/Pj799FNNmzbtpJ/BG4Z//PHHCtv3798fcC49PV3r1q3TiBEjNGvWLL+2zMzMgF1davps+/fvr3D6UWZmpt/rToeEhARlZ2eruLg4IGQfP35cBw8eVMOG/v/9HDx4sAYPHqy8vDx9/vnnWrBggV555RX94he/0FdffaXzzjtPkpSamlq2lem3336rZcuWafr06XrmmWdUWlqqZ5999rS9z2AI9QBwBqgXYXROYpzOqaQQ1+6KRvmz87X3UIGOh6EQV/nKu62SXRTigmM1bdpUQ4cO1bvvvqv58+dr3rx5kvwXyEru7SYl6cYbbwzoo6KpMdXRtWtXSdKaNWtUUlISMNVjxYoVAdd4n+eGG24I+Xm8/VZnlLxr167asGGDVqxYERDqt27dqj179qhNmzZBR+ZPha5du2rp0qVatWqVrrzySr+2VatWqaSkJGjtAZfLpf79+6t///5q1KiRnn76aS1cuLAs1HsZY3T++efr/PPP17Bhw5SWlqb583YlUIkAACAASURBVOcT6gEAp0fD2Cidf06Czj+n4kJcmbmF5bbmzAtLIa76MZF+C3Z9p/ZQiAt13V133aV3331XU6ZM0TfffKPGjRvr+uuv93uNdwvIFStW6IILLig7/9VXX2nixIk1un9qaqoGDBigJUuW6C9/+UvA7jcVhXTf5/Gtdrt9+3b9/ve/r/A+ycnugYCMjIyQn+2OO+7Qa6+9pueee05Dhw5VkyZNJLk/GDz66KMqLS3Vb3/725D7C4c77rhDS5cu1eOPP64VK1aUbUean5+vMWPGSJLfM61atUq9evUKKCDm/c2I9/pNmzapcePGAdOgyr+uthHqAeAsF1kvQi0902t6B65fU05+0YnKu1n+u/Vk5haokkF+HfUU4vo283BAW4SRzkmM86+8m+Qq+wCQEFf7c1Rxdhs4cKBat26tdevWSZLuv//+gPnav/nNb/TCCy9o9OjRWr58udq3b68tW7ZowYIFuuGGG/TWW2/V6BmmT5+unj17avTo0Vq8eLEuvPBCbd26VfPmzdOQIUP0/vvv+71+yJAhateunf785z/rP//5j7p27aqMjAwtWLBAgwcPrjC4X3HFFYqIiNDjjz+ujRs3qlEj985dTz75ZNDn6tWrl373u9/p+eefV5cuXTR8+HC5XC4tXLhQGzduVJ8+ffTYY4/V6L1X1y233KL09HS9/fbbZSPpxhjNnz9fO3bs0M0336xbb7217PUPPPCA9u7dq969e6t169aKjo7W+vXrtWzZMrVq1Uq/+tWvJElLlizRY489pp49e6pDhw5KSUnRnj17lJ6eroiIiNP+PoMh1AMAKuUtxPWz1OCFuLxz98uH/7xKCnGVWmnPoQLtOVRxIa6EuCi/EX5vMa6WSe5Rfgpx4VTzLpj1hlvfBbJe55xzjlavXq0xY8ZozZo1WrRokTp16qQZM2boqquuqnGob9++vT777DONGTNGH3/8sVasWKGf/exnmj9/vn766aeAUO9yubRs2TKNGTNGK1as0OrVq3Xuuefqqaee0sMPP1zh83Tu3FlvvPGG/vSnP2nGjBllVWcrC/WSu8hV165d9Ze//EVz5sxRcXGx2rZtq+eee06PPPJIrWz1OHfuXPXt29dv4Wvnzp31yCOP6L//+7/9Xjt27FjNmzdPX375pT7++GNFREQoLS1NY8eO1ejRo8s+3AwaNEgZGRlatWqV0tPTdfjwYTVv3lwDBgzQww8/rF69ep3291kRE46SvGcyY8z6bt26dVu/fn1tPwoAOIq1Vtl5RT5bc/rv2FNVIa7KREYYpTaK81+86zPKTyEuAE7UvXt3bdiwYYO1tnt1r+W/egCAU8IYo+T6MUqutBBXgXv+vs++/N7gX1gcfIvO46UnCnGt3hLYnuyK9gv8vvvyU4gLwJmIUA8AqBXuQlz11S6lfkCbtVY/HTlWbvHuia+fjoRWiOvr3cELcXl36PHbuYdCXAAcilAPAKhzjDFKaRirlIaxujhIIa7d2QWearue6T2ewL8nuzqFuH4KaG/SIKZs/r7vjj1pyRTiAlB3EeoBAI4THx2pjs0aqGOzBgFtpaVW+w8XBlTf9U7vyc4rqrTvn44c009BCnHFRkX4zd/3nd7TMolCXABqD6EeAHBGifApxHXZuYGFuI4UFp8Y3c+qXiGuwuJS/fDjUf3w49GANmOkZg1jT4zslxvpT3JFM8oP4JQh1AMAzioNQizE5bcvf3ZeSIW4MnMLlVlJIS7fBbstfbbpbNGIQlwAaoZQDwCAh18hrgrac/OLtSs7z29rTm/4D6UQ1+bMw9pcSSGusgW73sW7nmk+CfEU4gJQOUI9AAAhSoiP0s/iE4MW4tqXU1C2YNc9vSdPGdkFysjKC7kQ1yfbKinEVX7xblK8mifEKpJRfuCsR6gHACAMoiMj1LqxS60buwLavIW4Akb4PeE/M7fyQly5BcX6z95c/WdvbkCbbyGu8ot3WyW7KMQFnCX4Nx0AgFPMtxBX10oKcfmN7vtM8wm1EFdFklzRFS7ebUUhLuCMQqgHAKCWhVqIy3/xbmiFuLLzipQdrBBXvQilJsWVLdj1ju57PwBQiAtwDkI9AAB1WKiFuDI8o/y7ffblr7IQV0mptv+Up+0/5VXY3qRBjGfBbnzA9J4mDSjEBdQlhHoAABysqkJcPx4pPLEff7l9+UMtxLW+0kJc3mJccWqV7FLLpHilNopTbBSj/MDpRKgHAOAMFRFh1DwhTs0Tghfi2u0zf98b/ndn52tPGApxndiak0JcwKlGqAcA4CzVIDZK550TpfPOaRjQ5i3E5Tt/33ekP7egOGi/voW41lVSiMt3dN8b/s9JjFN0JFt0AtVFqAcAAAF8C3H1qqA9N7/YM3c/z2dffnfg35dTs0JczRPiyubu+47wt0pyUYgLCIJQDwAAqi0hPkoXxCfogtSEgLbiklLtPVTgtxd/RpZnxD+EQlx7cwq0N6fiQlwNYyOVluwO+C19Fu5SiAtnO0I9AAAIq6h61S/E5f3af7hQtpJR/sOFx7Vx72Ft3Bs4yh8ZYdSiUZzfvvytkk/s3NMgllF+nLnCFuqNMamSnpF0taRkSZmS5kuaYK0NXDZfcR8DPNdf5PlKkrTWWtsnhGuHS7pLUndJ9SUdkPSVpInW2s+q/YYAAEDYVacQl+/iXe9i3qoKce3Kcl9TkSRXtHt0v4JiXM0aUogLzhaWUG+MaSvpE0kpktIlfSeph6QHJV1tjOltrQ38HVqg+yRdJ6lQ0la5Q31V946U9IakWyRtkfSWpFxJzST1lDvkE+oBAHCAKgtxHT3mP7rv8/2BEAtxfVNJIa7AffldapkUp/hoJjegbgvXP6Ez5A70D1hrX/aeNMb8WdJDkv4g6d4Q+pks6Qm5PxS0lLQjhGsmyB3o/yDpaWut30d4Ywy/awMA4AxgjFFKg1ilNKi4EFdBUYl2H/LfmnNXlmch76ECFR2veSGutHKj/K0oxIU6wtjKJq6F0oF7lH6rpJ2S2vqGamNMA7mn4RhJKdbaiv9Nqbjf1nKH+qDTb4wxzSTtkrTBWtvzJN9CVc+xvlu3bt3Wr19/KroHAACngbcQl3fBru/0nt3Z+cqqohBXZXwLcZVN7/FM60ltFE8hLoSse/fu2rBhwwZrbffqXhuOkforPMfF5UfJrbVHjDFrJQ2UdJmkpWG4n6/hkqIl/cMYEydpsKR2ko5IWmOt/SbUjowxwVJ7pxo/JQAAqFW+hbgurbQQV75fMa6aFuKS3IW4/Lbm9Fm8m0whLoRJOEJ9R8/xhyDtW+QO9R0U/lB/iecYL/eUnTTfRmPMu5J+Y62teMUMAACAQi/E5d2m03c+f2WFuCRp/+FC7T9ccSEuV3S9gK0505JdSkuKVwsKcaEawhHqvRvU5gZp955PDMO9ykvxHJ+VtFbSMLk/XHSR9BdJN0o6KmlEVR0F+zWHZwS/WxieFQAAOFCohbhOfJ0Y6a+qEFdeUYm+239E3+0/EtDmLcRVfnTf+wEgMT46fG8Sjuf0pdzej6/ZkoZYa72b1n5ujBkqd8C/zRjzhLV2b608IQAAOKNVVYhrX05BucW7Jz4AHD12PGi/voW4Pt0evBCXe4Tf5Rf4KcR19glHqPeOxAf+k+x/PnD/qJrz9rnUJ9BLkqy1mcaYzyVdKeliSYR6AABwWkXVi1CrZJdaJVdciOuQZ5R/V1aeX+DfnZ2vzDAV4vLbmz+ZQlxnqnCE+u89xw5B2tt7jsHm3Ifj3sE+MHiLXsWdgnsDAACcNGOMklzRSnJF66KWgbOUC4tLtDenwG/+vnfxbkZ2vgqKS4L2XVUhrkbxUWVz91v57tyTTCEupwpHqF/uOQ40xkRUsKVlb0n5OjUFoD6W9JTcc+grcr7nGMp+9wAAAHVGbFQ9tW1SX22bBC/EVX46jzf8V1WI61B+sQ7l5wQvxNUozm/HHt9Rfgpx1U01/lux1m4zxiyWe4eb+yS97NM8QZJL0qu+e9QbYzp5rv2uhrdfLelrSX2MMddba+f53OMuSZ3l3kP/yxreBwAAoM7wLcTVvVXwQlyB+/LnhVaI62Ceth+suLxQ4/oxSkuK81Tb9d+XP4VCXLUmXB+1Rkn6RNJLxpgrJW2WdKnce9j/IHeVWF+bPUe/v3VjTB9Jd3p+9H4sbW+Mme19jbV2hM/31hhzu6SVkt41xrzvud/5kq6RlCfpdmtt8N9PAQAAnGHiouupQ9MG6tC0QUBbaanVgSPHyqrt+n1lVV2I6+DRYzp49Jg2ZASO8sdGRahlI/+R/VYU4jotwhLqPaP1F0t6RtLVkq6Vu5LsNEkTrLWHKrveRztJt5c7l1Lu3Ihy9/63MaabpHFy/7bgWkkHJf1d0rPW2u8FAAAASe5CXM0SYtUsIbbCQlxHjx0vm8azOztfu7LzlJFd4CnEla/iksoLcW05cFRbDlRSiMsn8Pt+TyGumjG2smXVkDFmfbdu3bqtXx+s4CwAAMDZoaTUKjO3oCz0e4txeaf35ORXXoirMt5CXL6j++7Fu66zphBX9+7dtWHDhg3B6idVhpUOAAAACEm9CKPURu6pNBUW4iooDly86ynGtS+nUCWVVOIKtRBX+ZH+VsnxSoiLOutH+Qn1AAAACIuEuCgltEhQlxbBC3GV35rT+wGgJoW4GsRG+o/ue4pxpSXF65zEs6MQF6EeAAAAp5xvIa6ft/dv8y3E5V6wm+e3eLeqQlxHKinEVS/CqEVinFolx5+Y3uMJ/2nJ8Wp4hhTiItQDAACgVlVViOvY8RLtOVRwYvFulv++/JUV4ioptWUfECrSKD7KM6XHpbQk7xQfl9KS49Ui0Tn1Swn1AAAAqNNiIisvxHXwaFHZ3P2MrALtys4rC/+hFeLK1Td7cv3OJ8ZH6eunB4b1fZxKhHoAAAA4ljFGTRrEqEmDmKCFuPYcKr9498RXsEJcaUnxp/rRw4pQDwAAgDNWXHQ9tW/aQO0rKcRVVm3XZ5vO85o3rIWnPXmEegAAAJyVfAtx9WgTOMrvJGf+/j4AAADAGY5QDwAAADgcoR4AAABwOEI9AAAA4HCEegAAAMDhCPUAAACAwxHqAQAAAIcj1AMAAAAOR6gHAAAAHI5QDwAAADgcoR4AAABwOEI9AAAA4HCEegAAAMDhCPUAAACAwxHqAQAAAIcj1AMAAAAOR6gHAAAAHI5QDwAAADgcoR4AAABwOEI9AAAA4HCEegAAAMDhCPUAAACAwxHqAQAAAIcj1AMAAAAOR6gHAAAAHI5QDwAAADgcoR4AAABwOEI9AAAA4HCEegAAAMDhCPUAAACAw4Ut1BtjUo0xrxtj9hljjhljdhpjXjTGNKpGHwOMMVOMMUuNMVnGGGuMWVPN53jSc501xlxV/XcCAAAAOEtkODoxxrSV9ImkFEnpkr6T1EPSg5KuNsb0ttZmhdDVfZKuk1QoaaukpGo+RzdJT0s6Kql+da4FAAAAnCpcI/Uz5A70D1hrh1lrx1hr+0uaKqmjpD+E2M9kSV3kDuRDqvMAxphYSX+T9IWkedW5FgAAAHCyGod6zyj9QEk7JU0v1zxOUp6k24wxrqr6stZ+aq3dZK0tOYlHmSipjaQRkkpP4noAAADAkcIxUn+F57jYWusXpq21RyStlRQv6bIw3KtCxpj+ck/1edxau+VU3QcAAACoi8Ixp76j5/hDkPYtco/kd5C0NAz382OMSZA0W9JqSS/VoJ/1QZo6nWyfAAAAwOkQjlCf4DnmBmn3nk8Mw70q8rLcC2r7WWvtKboHAAAAUGeFZfeb2mKMuVHSbZLus9Zur0lf1truQe6xXlK3mvQNAAAAnErhmFPvHYlPCNLuPZ8ThnuVMcYkSfqr3FN6Xgln3wAAAICThCPUf+85dgjS3t5zDDbn/mSlSWos6UpJpT4Fp6yk2z2vWeI5NzrM9wYAAADqjHBMv1nuOQ40xkT47oBjjGkgqbekfEmfheFevrIkvRak7XK5P0wslLRP0sYw3xsAAACoM2oc6q2124wxi+Xe4eY+uReuek2Q5JL0qrU2z3vSGNPJc+13Nbjvbkl3VtRmjJktd6j/s7X245O9BwAAAOAE4VooO0rSJ5JeMsZcKWmzpEvl3sP+B0lPlHv9Zs/R+J40xvTRiaBe33Ns7wnpkiRr7YgwPTMAAABwRghLqPeM1l8s6RlJV0u6VlKmpGmSJlhrD4XYVTudmA/vlVLu3IiaPS0AAABwZgnblpae6TAjQ3ytCXJ+ttyFpGr6LCNE+AcAAMBZIhy73wAAAACoRYR6AAAAwOEI9QAAAIDDEeoBAAAAhyPUAwAAAA5HqAcAAAAcjlAPAAAAOByhHgAAAHA4Qj0AAADgcIR6AAAAwOEI9QAAAIDDEeoBAAAAhyPUAwAAAA5HqAcAAAAcjlAPAAAAOByhHgAAAHA4Qj0AAADgcIR6AAAAwOEI9QAAAIDDEeoBAAAAhyPUAwAAAA5HqAcAAAAcjlAPAAAAOByhHgAAAHA4Qj0AAADgcIR6AAAAwOEI9QAAAIDDEeoBAAAAhyPUAwAAAA5HqAcAAAAcjlAPAAAAOByhHgAAAHA4Qj0AAADgcIR6AAAAwOEI9QAAAIDDEeoBAAAAhyPUAwAAAA5HqAcAAAAcLmyh3hiTaox53RizzxhzzBiz0xjzojGmUTX6GGCMmWKMWWqMyTLGWGPMmkpe38IY8z/GmIWe+x3zXLfEGHNDeN4ZAAAAULdFhqMTY0xbSZ9ISpGULuk7ST0kPSjpamNMb2ttVghd3SfpOkmFkrZKSqri9f8j6feSdkhaLmm/pFaSbpB0lTFmqrX24eq/IwAAAMA5whLqJc2QO9A/YK192XvSGPNnSQ9J+oOke0PoZ7KkJ+T+UNBS7rBemXWS+llrV/qeNMZ0lvSZpIeMMX+31q4P9Y0AAAAATlPj6TeeUfqBknZKml6ueZykPEm3GWNcVfVlrf3UWrvJWlsSyr2ttf8qH+g95zdLesvzY79Q+gIAAACcKhxz6q/wHBdba0t9G6y1RyStlRQv6bIw3Ks6ij3H46f5vgAAAMBpFY7pNx09xx+CtG+ReyS/g6SlYbhflYwxDSXdKMlKWhziNcGm6HQK13MBAAAAp0I4RuoTPMfcIO3e84lhuFeVjDFG0kxJTSW94pmKAwAAAJyxwrVQti6ZIukmSaslhbzzjbW2e0XnPSP43cLzaAAAAED4hWOk3jsSnxCk3Xs+Jwz3qpQx5nm5d9tZJelaa+2xU31PAAAAoLaFY6T+e8+xQ5D29p5jsDn3YWGMmSpptNz71f/CWpt/Ku8HAAAA1BXhGKlf7jkONMb49WeMaSCpt6R8ufeNDzvjNl3uQL9E0mACPQAAAM4mNQ711tptcu8w01ruirC+JkhySfqbtTbPe9IY08kYU+NdZTyLYv9X0ihJCyUNtdYW1LRfAAAAwEnCtVB2lKRPJL1kjLlS0mZJl8q9h/0PcleJ9eXdkcb4njTG9JF0p+fH+p5je2PMbO9rrLUjfC552vP6AklfSxrjzvl+vrbWzq/2OwIAAAAcIiyh3lq7zRhzsaRnJF0t6VpJmZKmSZpgrT0UYlftJN1e7lxKuXMjfL5v4znGSXo8SJ9vSCLUAwAA4IwVti0trbW7JY0M8bUBw+me87Mlza7GPUfIP+QDAAAAZ51wLJQFAAAAUIsI9QAAAIDDEeoBAAAAhyPUAwAAAA5HqAcAAAAcjlAPAAAAOByhHgAAAHA4Qj0AAADgcIR6AAAAwOEI9QAAAIDDEeoBAAAAhyPUAwAAAA5HqAcAAAAcjlAPAAAAOByhHgAAAHA4Qj0AAADgcIR6AAAAwOEI9QAAAIDDEeoBAAAAhyPUAwAAAA5HqAcAAAAcjlAPAAAAOByhHgAAAHA4Qj0AAADgcIR6AAAAwOEI9QAAAIDDEeoBAAAAhyPUAwAAAA5HqAcAAAAcjlAPAAAAOByhHgAAAHA4Qj0AAADgcIR6AAAAwOEI9QAAAIDDEeoBAAAAhyPUAwAAAA5HqAcAAAAcjlAPAAAAOByhHgAAAHC4sIV6Y0yqMeZ1Y8w+Y8wxY8xOY8yLxphG1ehjgDFmijFmqTEmyxhjjTFrQrjuPGPM28aYA8aYQmPM98aYCcaYuJq9KwAAAKDuiwxHJ8aYtpI+kZQiKV3Sd5J6SHpQ0tXGmN7W2qwQurpP0nWSCiVtlZQUwr0vlbRMUpSkdyTtltRf0tOSrjTGXGmtPVbtNwUAAAA4RLhG6mfIHegfsNYOs9aOsdb2lzRVUkdJfwixn8mSukiqL2lIVS82xtSTNEtSvKTh1tpbrLW/l3SppHcl9Zb0UHXfDAAAAOAkNQ71nlH6gZJ2SppernmcpDxJtxljXFX1Za391Fq7yVpbEuLt+0rqLGmVtfY9n35KJf3O8+O9xhgTYn8AAACA44RjpP4Kz3GxJ0yXsdYekbRW7pH0y8Jwr/L6e44flW+w1m6X9IOkVpLOPQX3BgAAAOqEcMyp7+g5/hCkfYvcI/kdJC0Nw/2qe+8Onq9tlXVkjFkfpKnTyT0aAAAAcHqEY6Q+wXPMDdLuPZ8YhnvVpXsDAAAAdUJYdr85E1hru1d03jOC3+00Pw4AAAAQsnCM1HtHwxOCtHvP54ThXnXp3gAAAECdEI5Q/73n2CFIe3vPMdi8d6feGwAAAKgTwhHql3uOA40xfv0ZYxrIvVd8vqTPwnCv8pZ5jleXbzDGnCt32N8lafspuDcAAABQJ9Q41Ftrt0laLKm13BVhfU2Q5JL0N2ttnvekMaaTMSYcu8qslLRZ0uXGmKE+/UfIXchKkv5qrbVhuBcAAABQJ4VroewoSZ9IeskYc6XcQftSufew/0HSE+Vev9lz9CsKZYzpI+lOz4/1Pcf2xpjZ3tdYa0f4fF9ijBkp94j9O8aYdyRlSLpS0sVy75E/tYbvDQAAAKjTwhLqrbXbjDEXS3pG7qkw10rKlDRN0gRr7aEQu2on6fZy51LKnRtR7t6fG2Mukfu3AgMlNZB7ys0zkiZZa49V790AAAAAzhK2LS2ttbsljQzxtSbI+dmSZp/Evb+VdFN1rwMAAADOBOFYKAsAAACgFhHqAQAAAIcj1AMAAAAOR6gHAAAAHI5QDwAAADgcoR4AAABwOEI9AAAA4HCEegAAAMDhCPUAAACAwxHqAQAAAIcj1AMAAAAOR6gHAAAAHI5QDwAAADgcoR4AAABwOEI9AAAA4HCEegAAAMDhCPUAAACAwxHqAQAAAIcj1AMAAAAOR6gHAAAAHI5QDwAAADgcoR4AAABwOEI9AAAA4HCEegAAAMDhCPUAAACAwxHqAQAAAIcj1AMAAAAOR6gHAAAAHI5QDwAAADgcoR4AAABwOEI9AAAA4HCEegAAAMDhCPUAAACAwxHqAQAAAIcj1AMAAAAOR6gHAAAAHI5QDwAAADgcoR4AAABwuLCFemNMqjHmdWPMPmPMMWPMTmPMi8aYRtXsJ8lz3U5PP/s8/aZWcs1gY8xiY8weY0yBMWa7MeafxpieNX9nAAAAQN0WllBvjGkrab2kkZLWSZoqabukByV9aoxJDrGfZEmfeq7b5ulnnaff9caYcyu4ZrKkBZK6SfpI0jRJGyRdJ2mtMea/avTmAAAAgDouMkz9zJCUIukBa+3L3pPGmD9LekjSHyTdG0I/f5TUQdKfrbWP+PTzgNxhfYakq33ON5P0qKQfJf3MWnvAp+0KScskPSPp/530OwMAAADquBqP1HtG6QdK2ilpernmcZLyJN1mjHFV0U99Sbd5Xj++XPNfJO2SNKjcaH0rud/D576BXpKstcslHZHUpBpvBwAAAHCccEy/ucJzXGytLfVtsNYekbRWUryky6ro5zJJcZLWeq7z7adU0qJy95OkLZKKJPUwxjT2vcYYc7mkBpI+Dv2tAAAAAM4Tjuk3HT3HH4K0b5F7JL+DpKU17EeefiRJ1tpsY8zvJf1Z0rfGmPmSsiS1lTRU0hJJ91T1BiTJGLM+SFOnUK4HAAAAaks4Qn2C55gbpN17PvFU9GOtfdEYs1PS65Lu8mnaKml2+Wk5AAAAwJnG8fvUG2N+J+kdSbPlHqF3Seou9+47fzfGPB9KP9ba7hV9SfruFD06AAAAEBbhCPXeEfSEIO3e8znh7scY00/SZEnvWWsfttZut9bmW2s3SLpe0l5Jj1S0FSYAAABwpghHqP/ec+wQpL295xhsrnxN+vmF57i8/Iuttfly73EfIalrFfcGAAAAHCscod4bqAcaY/z6M8Y0kNRbUr6kz6ro5zNJBZJ6e67z7SdC7sW2vveTpBjPMdi2ld7zRVXcGwAAAHCsGod6a+02SYsltZZ0X7nmCXLPcf+btTbPe9IY08kY47erjLX2qKS/eV4/vlw/93v6X2St3e5zfrXneLcxpoXvBcaYa+T+QFEo6ZPqvi8AAADAKcJVUXaU3MH5JWPMlZI2S7pU7j3lf5D0RLnXb/YcTbnzYyX1k/SwMeYiuafPdJZ0naQDCvzQ8I7c+9BfJWmzMWaepP2ea37h6X+MtTarhu8PAAAAqLPCsvuNZ7T+Yrl3oLlU0iNy70QzTdJloYZqz+t6SnpJUjtPP5dKmiWpu+c+vq8vlXStpIckfSv34thH5C5k9aGkQdbaaTV8ewAAAECdFq6Rellrd0saGeJry4/Q+7ZlS3rQ8xVKX8WSXvR8AQAAAGcdx+9TDwAAAJztCPUAAACAwxHqAQAAAIcj1AMAAAAOR6gHAAAAHI5QDwAAADgcoR4AAABwOEI9AAAA4HCEegAAAMDhCPUAAACAwxHqAQAAAIcj1AMAAAAOR6gHAAAAHI5QDwAAADgcoR4AAABwOEI9AAAA4HCEegAAAMDhCPUAAACAwxHqAQAAAIcj1AMAAAAOR6gHAAAAHI5QDwAAADgcoR4AAABwOEI9AAAA4HCEegAAAMDhCPUAAACAwxHqAQAAAIcjd5IxjQAAGglJREFU1AMAAAAOR6gHAAAAHI5QDwAAADgcoR4AAABwOEI9AAAA4HCEegAAAMDhCPUAAACAwxHqAQAAAIcj1APA/2/v3oMku+rDjn9/s7szOzM7+5pdCWwhFiStVinAWLL1YG0sRcmisiqWgqFCBRQjB7swYMkgXKkCR5Zc4KScWCXxqriwRUB2QoXEICcQpAoogCUUYhWEVEovJK0e6LU7+56Zfc2c/HFuQ6u3e/r2zJ3puZrvp+rUne577+lz6k53/+7tc35XkqSaM6iXJEmSas6gXpIkSao5g3pJkiSp5ioL6iPijIi4PSKejYhjEbE7Im6NiE091rO52G93Uc+zRb1ndNnv8oj4ckQ837TfXRHxqwvrmSRJkrS8ra6ikog4C7gPOA24E3gIuBC4HrgiInamlCZK1DNe1LMd+CbwRWAHcC1wZURcklJ6vM1+fwL8PvAM8DfAXmArcAFwKfC1BXZRkiRJWrYqCeqBz5AD+utSSp9sPBkRtwAfBD4OvLdEPX9MDuhvSSnd0FTPdcBtxetc0bxDRPwWOaD/PPDbKaXjLevXzKdDkiRJUl0sePhNcZV+F7Ab+HTL6j8EJoFrImK0Sz3rgGuK7W9qWf0p4EngLRHx2qZ9hsgnDE/RJqAHSCmd6KE7kiRJUu1UMab+smJ5d0pptnlFSukwcC8wAlzcpZ6LgWHg3mK/5npmgbtaXg/gH5KH2fw1MBsRV0bEv4iI6yPiknn1RpIkSaqZKobfnFssH+mw/lHylfztwDcWWA9FPQ2/WCyPAt8HXte8Q0R8G3hbSmnPHK/b2PaBDqt2dNtXkiRJ6qcqrtRvKJYHO6xvPL9xEeo5rVj+PpCAXwbGgDcAdwNvBr7U5XUlSZKkWqtqomy/NE5KTgK/llLaXTz+vxHxj4GHgV8psuZ8d66KUkoXtHu+uIJ/fkXtlSRJkipXxZX6xhX0DR3WN54/sAj1NP7+flNAD0BKaYqfjsO/sMtrS5IkSbVVRVD/cLHc3mH9OcWy01j5hdTT2KfTCcP+Yjnc5bUlSZKk2qoiqL+nWO6KiJfUFxFjwE5gCri/Sz33A9PAzmK/5noGyJNtm18P8sTbBPy91tcuNCbOPtGtE5IkSVJdLTioTyk9Rp6Uug14f8vqm4FR4I6U0mTjyYjYEREvySqTUjoC3FFsf1NLPR8o6r+r+Y6yKaUngf8KnEm+e+1PRMQu4C3kq/hfn1fnJEmSpBqoaqLs+4D7gE9ExOXAg8BF5JzyjwAfbdn+wWIZLc9/BLgU+FBEvBH4HnAecBXwIqeeNFA89/PALRFxJTm15WuAq4EZ4D0ppU4ZdSRJkqTaq2L4TeNq/S8A/54czN8AnAXcBlycUpooWc8EcAnwCeDsop6LgM8BFxSv07rPM8AF5LvOnkO+Yn8p+Qr+zpTSf1lA1yRJkqRlr7KUlimlp4FrS27beoW+ed0+cmB+fadt2uyzB/jdokiSJEkrSt3z1L98ffl34OgBGBmH0S0wsqVpOf7Tx2tM7CNJkrTSGdQvV4/fA4ef677dmtGXBvmNoH90a/sTgcFRiI4/lEiSJKmGDOqXo5Rgcm+5bU9MwoFJOPBUue1Xrz31an/bx1vyrwRrN3gSIEmStMwZ1C9HKcFv/E0O7Kf2wuREsWzzePZEb3WfPAqHnsmljIE1TUOAWocCtRkaNLwJBiqZfy1JkqSSDOqXo4EBePWbum+XEhw9CFMTTQF/lxOBk0d7a8vsCTjyfC5lxEAO9jsG/i2PhzfDKv8NJUmSFsJoqs4iYHhjLuNndd8+JTg+2SHo39vm5GACjh/prU1pFib35LKnVCdy++e6+t86NGj1YG9tkiRJepkzqF9JImBoXS6btpXb58R0S7Df5heAyT0//ftYr/f5SjC9P5eJR8vtMrS+JfhvCvp/MkHYDEGSJGnlMKjX3NYMw4Yzcinj5PF8EtDx6n/LicH0fiD11qZjh3LZ/0TJPnTIENRuYvDoFhhc5+RgSZJUKwb1qtbqQVj/ylzKmDmZA/syQ4EayzTTW5t6zRC0aqj8xODRcVi70ZMASZLUVwb16q9Vq2Hd1lzKmJ3NN+V6SdC/p9oMQTPH4NCPcyljYHXT5ODGcqsZgiRJ0pIxqFe9DAzAyOZctpzTffuU8lCdOa/+tzw+Od1bm2ZPwpEXcikjBnLWn45DgVoej4ybIUiSJM3JSEEvbxH5BlprN5TLEAQ5Q1CZewQ0lvPJEDRV7F/W2o1dhgK1PF491FubJElSrRnUS60GR3PZ9Opy2584Wu4eAY3HR3vNEEQecnT0AEz8qNz2c2UIanciMDjSe5skSdKyYVAvLdSatb1lCJo5UX4o0NRemNrH4mcIGmkT/M9xz4ChMScHS5K0jBjUS0tt1RoYe0UuZczO5AxBc6UGndyzwAxBU3DwqVxK9WGoCPrnmA/QfM8AMwRJkrSoDOql5W5gVREkbym3fdsMQV2GBs0c761NM8fg8LO5lOpDuwxBcwwNGt6U+y1JkkoxqJdebuaVIehw54nA7e4ofGKqtzbNK0PQpvITg0fG8y8gkiStUAb10koXAWvX57L5teX2OT7VEvTvmfvXgOOHe2tTmi3uTDwBex8ut8/aDS1Df8wQJElaOQzqJfVucAQGz4SNZ5bb/uSx8hODJ/fm4UO9Onowl32PlezDWImhQE2PB0d7b5MkSUvEoF7S4ls9BBt+NpcyZk7krD9lU4VO78tX93tx/HAu+3eX7MNwuaFAjb/NECRJWkIG9ZKWn1VrYOz0XMookyGo+fHURB7n34uT03Dw6VxK9WGw/MTgkSJD0MBAb22SJKlgUC+p/nrNEJRSHuLTdWJw0+OZY721aeZ4bxmCYlXTVf9uE4O35InQZgiSJBUM6iWtPBE5u87wJuDs7tunBMePdAj6G/cKWGCGoDQDky/mUq4Tuf1z/QJghiBJWjEM6iWpm4g8Rn5oDDa/ptw+p2QImmto0ES+A3BPUp5LML0PeKTcLs0ZgsoMDVqztsc2SZL6xaBekhbDfDIEtbsnQKehQdP7e29TzxmC1pUbCtQ4GRgcdXKwJPWJQb0kLQerh2D9z+RSxszJfJW+7RCgqjIEHcnlwJMl+7C289Cfdo+H1nsSIEkVMaiXpDpatRrWnZZLGbOz+ep+2YnBU3vnkSHoKBx6JpdSfRjMAX7ZLEFmCJKkjgzqJWklGBjIgfLoOGw9t/v2KeWhOl3nAxSPJ/fMM0PQc7mUEaty1p9uvwA0Hg9vzic/krQC+GknSTpVBAxvzGX8rO7bd80Q1OZE4MRkb21KM/nkYXIP7CnVie4ZgppPBEbGYfVgb22SpGXCoF6StHDzyRB0Yrr8xODJCTh2sMdGzSND0NCGluB/jonBo1tgzXCPbZKkxWFQL0nqjzXDsPFVuZRx8ngO9OdMFdr093wyBB07mMu+x0v2YbT9fIDRrWYIkrSkDOolSfWwehDWvzKXMtplCJprYvDURO8Zgk5MwoFJOPBUyT6sLT8xeGQ831vAkwBJJRjUS5JenuaTIejogXLzARqPZ0/01qZeMwQNrGkaAlTingHDm8wQJK1QBvWSJEEOhkc258L27tunlO8E/JMr/nu6nwicPNpbm2ZPwJHncykjBprShJohSFpJfCdLkjQfEXl4zNoNPWQImiw5Mbh4fPxIb21Ksz1mCCJf3S87MXhkixmCpGXKoF6SpKUQAUPrctm0rdw+J6ZPzQI019Cgo71mCCJPKJ7eDxOPltt+aH1L8N8pVehWMwRJS8igXpKk5WrNMGw4I5cySmUIalo/vR9IvbXp2KFc9j9Rsg8dMgR1umfA4DonB0vzYFAvSdLLRa8ZgmZnYGpfuaFAjWWa6a1NvWYIWjVUfmLw6Dis3ehJgESFQX1EnAH8EXAFMA48B3wFuDmlVDpZcERsBm4ErgZeCUwAXwduTCl1TRcQEe8C7ige/lZK6c976YckSSvGwCpYtzWXMhoZgjr9AjC5Z+EZgmaOwaEf51KqD6ubJgc3llvNEKQVp5KgPiLOAu4DTgPuBB4CLgSuB66IiJ0ppYkS9YwX9WwHvgl8EdgBXAtcGRGXpJQ63hEkIl4FfAo4AqxbUKckSdJLNWcI2nJO9+1PyRBU4teAk9O9tWn2JBx5IZcyYiBn/ek4FKjl8ci4GYJUC1X9l36GHNBfl1L6ZOPJiLgF+CDwceC9Jer5Y3JAf0tK6Yameq4Dbite54p2O0ZEAJ8jX9n/a+DD8+qJJEmqRq8ZgiBnCCo7MXhyAo4f7q1Naba42dje8vus3dhlKFDL49VDvbVJqsCCg/riKv0uYDfw6ZbVfwj8NnBNRNyQUpqco551wDXAJHBTy+pPAR8C3hIRr+1wtf464O8DlxZLSZJUN4OjuWx6dbntTxx96eTgbjcPm0+GoKMHcpn4Uck+jOUr/qNbu08MHtkCgyO9t0lqUcWV+suK5d0pvfT+2imlwxFxLznovxj4xhz1XAwMF/W85LQ7pTQbEXeRTxAuA14S1EfEecC/Bm5LKX07IgzqJUlaCdashQ0/m0sZMyfKDwWa2psnEveaIej44Vz27y7Zh5E2wf8c9wwYGnNysE5RRVB/brF8pMP6R8lB/XbmDurL1AMtt/mLiNXkibFPAR/p1thOIuKBDqt2zLdOSZK0zKxaA2OvyKWM2Zmc+rPbLwA/mSg8nwxBU3DwqVxK9WGoCPrnmA/Q/CuBGYJWhCqC+g3FstPvWY3nNy5SPTcCPw/8Ukqpx9k1kiRJcxhYVQTJW8pt3y1DULvHM8d7a9PMMTj8bC6l+tAuQ9Ac9wwY3pT7rVqp9XTuiLiIfHX+T1NK311IXSmlCzq8xgPA+QupW5IkrRDzyhB0uEPQ3zo0qFh/Yqq3Ns0rQ9Cm8hODR8bzLyDqqyqC+sYV9A0d1jeeP1BlPcWwmy+Qh+v8y+7NlCRJWmYiYO36XDa/ttw+x6c6zwdo9+vAvDIETeSy9+Fy+6zd0OEXgA73DDBDUOWqCOobR3t7h/WN09ROY+XnW8+6pm2PRvuxYp+NiM+SJ9D+XpfXlyRJWv4GR2DwTNh4ZrntTx4rPzF4cm8ePtSrowdz2fdYyT6MlRgK1PR4cLT3Nq0wVQT19xTLXREx0JwBJyLGgJ3AFHB/l3ruB6aBnREx1pwBJyIGyJNtm1/vGPAXHeo6nzzO/m/JJwsLGpojSZJUW6uH5pEhaF+5+QCTe2F6X76634teMwStHi4/FGh0CwytX3GTgxcc1KeUHouIu8lB9/uBTzatvhkYBf6sOUd9ROwo9n2oqZ4jEXEHOW3lTcANTfV8ANgG3NXIUV9Min1PuzZFxE3koP7zKaU/X1gPJUmSVpBVa2Ds9FzKmJ2B6QNFkL+n+4nA1EQe59+Lk9Nw8OlcSvVhsPzE4JEiQ9DAQG9tWmaqmij7PuA+4BMRcTnwIHAROaf8I8BHW7Z/sFi2nkJ9hHzzqA9FxBuB7wHnAVcBL5JPGiRJkrRcDKwqbrY1DlvP7b59SnmIT9eJwU2PZ4711qaZ471lCIpVTVf9i+WmbfAPburtdfuokqC+uFr/C8AfAVcAvwo8B9wG3JxS2l+ynomIuIR8J9qrgV8GJoDPATemlJ6por2SJEnqk4icXWd4E3B29+1TguNHOgT9zb8I7Jl/hqA0A5Mv5tIwfs7KC+oBUkpPA9eW3LbjIKeU0j7g+qLMty03kYfwSJIkqc4i8l10h8Zg82vK7TNXhqBThgZNwLFDp9YxMl5tPxZZrfPUS5IkSaeYT4ag1nsCDI0tbhsrZlAvSZKklW31EKz/mVxqqt7TfCVJkiQZ1EuSJEl1Z1AvSZIk1ZxBvSRJklRzBvWSJElSzRnUS5IkSTVnUC9JkiTVnEG9JEmSVHMG9ZIkSVLNGdRLkiRJNWdQL0mSJNWcQb0kSZJUcwb1kiRJUs0Z1EuSJEk1Z1AvSZIk1ZxBvSRJklRzkVLqdxuWtYiYGB4e3nzeeef1uymSJEl6GXvwwQeZnp7el1Ia73Vfg/ouIuIJYD2wuw8vv6NYPtSH19bS8BivDB7nlcHjvDJ4nF/++nmMtwGHUkqv6XVHg/plLCIeAEgpXdDvtmhxeIxXBo/zyuBxXhk8zi9/dT3GjqmXJEmSas6gXpIkSao5g3pJkiSp5gzqJUmSpJozqJckSZJqzuw3kiRJUs15pV6SJEmqOYN6SZIkqeYM6iVJkqSaM6iXJEmSas6gXpIkSao5g3pJkiSp5gzqJUmSpJozqF9CEXFGRNweEc9GxLGI2B0Rt0bEph7r2Vzst7uo59mi3jMWq+0qb6HHOSJGI+KdEfEfIuKhiJiMiMMR8XcRcUNEDC52H9RdVe/nljrfHBEzEZEi4mNVtle9q/IYR8T5xXv6maKuFyLiWxHxzxaj7Sqvwu/mX4qIO4v9j0bEUxHxtYi4YrHarnIi4m0R8cmI+E5EHCo+Y/9ynnVV/tlfFW8+tUQi4izgPuA04E7gIeBC4DLgYWBnSmmiRD3jRT3bgW8C/xvYAVwFvAhcklJ6fDH6oO6qOM7FF8B/B/YB9wA/AjYBvwa8oqj/8pTS0UXqhrqo6v3cUucY8ENgC7AO+HhK6Q+qbLfKq/IYR8QHgNuA/cBXgR8Dm4HXAc+klN5ReQdUSoXfzb8DfAaYBL4MPAOcAbwVGAH+IKX08cXog7qLiB8APwccIR+bHcBfpZTe1WM9lX/2VyqlZFmCAtwFJOB3W56/pXj+35Ws58+K7f+05fnriue/3u++ruRSxXEG3gi8ExhseX4MeKCo54Z+93Ull6rezy373k4+kftIUcfH+t3PlVwq/MzeBcwW9Y21Wb+m331dyaWiz+w1wAFgGji3Zd15wFFgChjqd39XaiEH3ecAAVxaHNu/7Mf/y2IWr9QvgeLM7kfAbuCslNJs07ox4DnyP9ppKaXJOepZR74aPwu8MqV0uGndAPA48OriNbxav8SqOs5dXuOfAn8F/LeU0j9acKPVs8U4zhFxFfAV4BpgNfA5vFLfN1Ue44j4P8DZwJmpn1fwdIoKv5tPB54HfphS+rk2638IvB7Y4v9A/0XEpeRfwXu6Ur8U3/EL5Zj6pXFZsby7+Z8AoAjM7yX/PHdxl3ouBoaBe5sD+qKexpWg5tfT0qrqOM/lRLE8uYA6tDCVHueIOA34LPCVlNK8xniqcpUc44h4HfAG4G5gX0RcFhEfLubGXF5cjFH/VPVefhHYA2yPiHOaV0TEdvIV4h8Y0NfeUnzHL4gfKEvj3GL5SIf1jxbL7UtUjxbHUhyf3yyWX19AHVqYqo/zZ8mfxe9dSKNUqaqO8S8WyxeB/0meB/VvgH8L/A/gBxFx9vybqQWq5DinPOTh/eT38QMR8fmI+FcR8QXykMn/B7y9gvaqv5Z9DLa6Xy+8wmwolgc7rG88v3GJ6tHiWNTjU0y2uwL4AXn8tfqjsuMcEb9JngD9T1JKL1TQNlWjqmN8WrH85+TJsVcCfwucDtwIvAv4akS8PqV0fP7N1TxV9l5OKX0pIp4F/iPQnNHoBfJwOofE1t+yj8G8Ui/VQES8FbiVPG7z11NKJ7rsomUuIraRj+mXUkr/qb+t0SJpfMeuAt6RUvpaSulQSulRcuD3d+Srer/erwaqGhHxLvKvL98hT44dKZbfAD4FfLF/rdNKYVC/NBpnbxs6rG88f2CJ6tHiWJTjExFXk78QXgQudRJ031V1nG8nZ8t4XxWNUqWqOsaN9c+nlL7bvKIYsnFn8fDCnluoKlRynItx87eTh9lck1J6KKU0nVJ6iDz5/QHg7cUETdXXso/BDOqXxsPFstM4q8bEmk7jtKquR4uj8uMTEW8HvkT+CfdXUkoPd9lFi6+q43w+eXjGnuJGKCkiEvmneoCPFs99ZWHN1TxU/Znd6Ut+f7EcLtkuVauq47yLnNbyW20mUM4C3y4eXjCfRmrZWPYxmGPql8Y9xXJXRAy0SYO0k5zD9v4u9dxPvrK3MyLG2qS03NXyelpaVR3nxj7vBD5PHot7mVfol42qjvMXyD/RtzoHeDN57sQDwPcX3GL1qsrP7ElgW0SMtklz97pi+UQFbVbvqjrOQ8Vya4f1jeedN1FvlX7HLwav1C+BlNJj5JRm28gz5JvdDIwCdzR/4EfEjojY0VLPEeCOYvubWur5QFH/XQZ//VHVcS6e/w1y0PcU8GaP6fJR4fv5upTSe1oLP71S/9XiuU8vWmfUVoXHeAr4C2At8LGIiKbtXw+8m5ye9j9X3wt1U+Fn9neK5dsi4g3NKyLijcDbyDcm+mZ1rddiiYg1xXE+q/n5+fy/LDVvPrVE2txa+EHgInLe00eANzXnsC1+hielFC31jBf1bCd/QHyPPBnnKvKY6zcV/3jqgyqOc0RcRp5wNUAep/l0m5c6kFK6dZG6oS6qej93qPvdePOpvqvwM3s98C3ynaL/FzmX9enAW8nDbn4vpXTbYvdH7VV4nG8HriVfjf8y8CQ5+LsaGARuTSl9cJG7ow6KuWlXFw9fAbyFnJGocUK2N6X04WLbbeRfz55MKW1rqaen/5clV9WtaS2lbi/8KvKX9XPkN/6T5OwXm9psmyjmUrVZtxm4rdj/eFHf7cAZ/e6jZeHHmXz1LnUpu/vdz5Veqno/t9m2cfw/1u8+rvRS4Wf2OuDj5C/9Y+Qx9ncDu/rdR0s1x5l8J9F3k+9HsJ/8C8w+cvabd/S7jyu9kEc3lPpOJZ+Mdfye7eX/ZamLV+olSZKkmnNMvSRJklRzBvWSJElSzRnUS5IkSTVnUC9JkiTVnEG9JEmSVHMG9ZIkSVLNGdRLkiRJNWdQL0mSJNWcQb0kSZJUcwb1kiRJUs0Z1EuSJEk1Z1AvSZIk1ZxBvSRJklRzBvWSJElSzRnUS5IkSTVnUC9JkiTVnEG9JEmSVHP/HzXRkMA7E4HDAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 378,
              "height": 248
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDKnvAKWEvi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}